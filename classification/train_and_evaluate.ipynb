{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "N_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3 # this equals to 0.001\n",
    "WEIGHT_DECAY = 1e-3 # this equals to 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST(root=\"../mnist_tr/\", download=True, transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we should define a validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate indices: instead of the actual data we pass in integers instead\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(mnist_train)),\n",
    "    mnist_train.targets,\n",
    "    test_size=0.1,\n",
    ")\n",
    "\n",
    "# generate subset based on indices\n",
    "tr_dataset = Subset(mnist_train, train_indices)\n",
    "val_dataset = Subset(mnist_train, val_indices)\n",
    "\n",
    "tr_dataloader = DataLoader(tr_dataset, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Sequential, Linear, ReLU, Conv2d, MaxPool2d\n",
    "from torch import Tensor # Only for type-annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers: BatchNorm, ReLU, Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(Module):\n",
    "    def __init__(self, n_channels: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.convs = Sequential(\n",
    "            Conv2d(n_channels, 6, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2),\n",
    "            Conv2d(6, 16, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fcs = Sequential(\n",
    "            Linear(16 * 5 * 5, 120), \n",
    "            ReLU(),\n",
    "            Linear(120, 84), \n",
    "            ReLU(),\n",
    "            Linear(84, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.convs(x)\n",
    "        x.flatten(x, 1)\n",
    "        x = self.fcs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training: optimizers and backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\") # If on macos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets pick an optimizer and loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model:\n",
    "model = ImageClassifier().to(DEVICE)\n",
    "\n",
    "# Define loss:\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer, you need to attach your model(s) parameters\n",
    "# to an optimizer object that will be responsible for updating your model.\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PyTorch has 2 different Adam optimizers, Adam is ... and AdamW is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flatten() received an invalid combination of arguments - got (Tensor, int), but expected one of:\n * (int start_dim, int end_dim, name out_dim)\n * (int start_dim, int end_dim)\n      didn't match because some of the arguments have invalid types: (!Tensor!, int)\n * (name start_dim, name end_dim, name out_dim)\n * (tuple of names dims, name out_dim)\n      didn't match because some of the arguments have invalid types: (!Tensor!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m input_data \u001b[39m=\u001b[39m input_data\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m target_data \u001b[39m=\u001b[39m target_data\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m pred_data \u001b[39m=\u001b[39m model(input_data)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m tr_loss \u001b[39m=\u001b[39m loss_fn(pred_data, target_data)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# First step is to clear the calculated gradients from the previous iteration.\u001b[39;00m\n",
      "File \u001b[0;32m~/GitRepos/basira-deep-learning-tutorials/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/GitRepos/basira-deep-learning-tutorials/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     x\u001b[39m.\u001b[39;49mflatten(x, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfcs(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/oytun/GitRepos/basira-deep-learning-tutorials/classification/train_and_evaluate.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: flatten() received an invalid combination of arguments - got (Tensor, int), but expected one of:\n * (int start_dim, int end_dim, name out_dim)\n * (int start_dim, int end_dim)\n      didn't match because some of the arguments have invalid types: (!Tensor!, int)\n * (name start_dim, name end_dim, name out_dim)\n * (tuple of names dims, name out_dim)\n      didn't match because some of the arguments have invalid types: (!Tensor!, !int!)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    tr_losses = []\n",
    "    for input_data, target_data in tr_dataloader:\n",
    "        # Dont forget to move your tensors to your device of preferrence !\n",
    "        input_data = input_data.to(DEVICE)\n",
    "        target_data = target_data.to(DEVICE)\n",
    "        pred_data = model(input_data)\n",
    "        tr_loss = loss_fn(pred_data, target_data)\n",
    "\n",
    "        # First step is to clear the calculated gradients from the previous iteration.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Loss should be 1-value tensor and is a leaf in the gradient tree,\n",
    "        # Based on the gradient functions attached to the tensors (grad_fn), automatic\n",
    "        # backpropagation will calculate all gradients in the background.\n",
    "        tr_loss.backward()\n",
    "\n",
    "        # Optimizer object is responsible for updating model weights and biases,\n",
    "        # after the gradients are calculated.\n",
    "        optimizer.step()\n",
    "\n",
    "        # tensor.detach() function breaks the gradient tree and returns the tensor only including the data !\n",
    "        # Thats why you are only allowed to do that after you finish the gradient calculations.\n",
    "        tr_losses.append(tr_loss.detach())\n",
    "    \n",
    "    # tensor.item() returns the one and only attached value here: e.g., tensor((0.00135)) -> 0.00135\n",
    "    avg_tr_loss = torch.stack(tr_losses).mean().item()\n",
    "\n",
    "    # After a successful training iteration, we can run a validation loop to monitor model's performance:\n",
    "    # Since there will be no backpropagation on the validation step, it is unnecessary to store gradients.\n",
    "    # Therefore we use torch.no_grad to disable all gradient functions during validation for memory efficiency.\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for input_data, target_data in val_dataloader:\n",
    "            # Dont forget to move your tensors to your device of preferrence !\n",
    "            input_data = input_data.to(DEVICE)\n",
    "            target_data = target_data.to(DEVICE)\n",
    "            pred_data = model(input_data)\n",
    "            val_loss = loss_fn(pred_data, target_data)\n",
    "            val_losses.append(val_loss.detach())\n",
    "        avg_val_loss = torch.stack(val_losses).mean().item()\n",
    "\n",
    "    print(f\"Epoch: {epoch}/{N_EPOCHS}, Avg.Tr.Loss: {avg_tr_loss}, Avg.Val.Loss: {avg_val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial that your testing set is completely disjoint from your training and validation sets, plus it should have the correct representation of the use cases of your model in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect test results one by one (no-batch), because they will be used to calculate metrics.\n",
    "mnist_test = MNIST(root=\"../mnist_test/\", download=True, train=False, transform=ToTensor())\n",
    "\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_logits = []\n",
    "    test_labels = []\n",
    "    for input_data, target_data in test_dataloader:\n",
    "        # Dont forget to move your tensors to your device of preferrence !\n",
    "        input_data = input_data.to(DEVICE)\n",
    "        target_data = target_data.to(DEVICE)\n",
    "        pred_data = model(input_data)\n",
    "        test_logits.append(test_logits)\n",
    "        pred_class = torch.argmax(test_logits)\n",
    "        test_preds.append(pred_class)\n",
    "        test_labels.append(target_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here lets take a look at the basic classification metrics: accuracy and f1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to visualize our results for better interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can plot a ROC-AUC curve to investigate the model confidence on its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the multi-class confusion matrix is crucial to see the model behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your model in production ! Dont forget to apply the preprocessing steps if there is any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
